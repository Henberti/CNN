{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import Cnn\n",
    "\n",
    "cnn = Cnn(x_train[:2000],y_train[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 ... 5 2 0]\n",
      "loss=2.3012294624329868\n",
      "[3 0 9 ... 3 8 9]\n",
      "0.1655\n",
      "loss=2.1018389773820476\n",
      "[2 0 4 ... 2 4 0]\n",
      "0.3505\n",
      "loss=3.04982162588353\n",
      "[7 9 9 ... 9 1 9]\n",
      "0.307\n",
      "loss=1.7614782355427718\n",
      "[5 0 4 ... 6 6 0]\n",
      "0.443\n",
      "loss=1.661759414842048\n",
      "[3 0 4 ... 0 3 0]\n",
      "0.4095\n",
      "loss=1.5358931003082612\n",
      "[3 0 4 ... 2 1 2]\n",
      "0.437\n",
      "loss=1.3014836465693524\n",
      "[5 0 4 ... 5 1 0]\n",
      "0.604\n",
      "loss=1.2269661450130085\n",
      "[5 0 4 ... 5 8 0]\n",
      "0.538\n",
      "loss=1.0205758186970357\n",
      "[3 0 4 ... 5 8 0]\n",
      "0.6805\n",
      "loss=0.8846218081678119\n",
      "[3 0 4 ... 0 8 0]\n",
      "0.7195\n",
      "loss=0.8163825052961717\n",
      "[3 0 4 ... 0 1 0]\n",
      "0.72\n",
      "loss=0.7163547647363677\n",
      "[3 0 4 ... 5 1 0]\n",
      "0.783\n",
      "loss=0.6684589775353355\n",
      "[3 0 4 ... 5 1 0]\n",
      "0.7845\n",
      "loss=0.6278753523565258\n",
      "[3 0 4 ... 5 8 0]\n",
      "0.7995\n",
      "loss=0.5752983118272692\n",
      "[3 0 4 ... 5 2 0]\n",
      "0.8235\n",
      "loss=0.5331967492518745\n",
      "[3 0 4 ... 5 2 0]\n",
      "0.833\n",
      "loss=0.49326245398608937\n",
      "[3 0 4 ... 5 2 0]\n",
      "0.8475\n",
      "loss=0.45733611999648677\n",
      "[3 0 4 ... 5 2 0]\n",
      "0.8545\n",
      "loss=0.4221222850376775\n",
      "[3 0 4 ... 5 2 0]\n",
      "0.873\n",
      "loss=0.4023378482149563\n",
      "[3 0 4 ... 5 2 0]\n",
      "0.873\n",
      "loss=0.38078940744360645\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.885\n",
      "loss=0.35169608591585183\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.8895\n",
      "loss=0.34249022406828195\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.893\n",
      "loss=0.3212711719223613\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.8995\n",
      "loss=0.2904809673600648\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.913\n",
      "loss=0.27601249460377647\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9185\n",
      "loss=0.26125333740968987\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.921\n",
      "loss=0.24346495587935976\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.922\n",
      "loss=0.22549818817356243\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.93\n",
      "loss=0.21671434648207782\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9375\n",
      "loss=0.2036929633473013\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.94\n",
      "loss=0.1908737258384324\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.945\n",
      "loss=0.1821563265415635\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.947\n",
      "loss=0.174514430699192\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.951\n",
      "loss=0.1740145798409624\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9465\n",
      "loss=0.1607182687283282\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9565\n",
      "loss=0.15949255185467448\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.957\n",
      "loss=0.1471157368745454\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.965\n",
      "loss=0.14609493418553024\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.965\n",
      "loss=0.13241991885992918\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.971\n",
      "loss=0.1328286264860686\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.968\n",
      "loss=0.12735811861644658\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.973\n",
      "loss=0.12132734130016987\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.974\n",
      "loss=0.11535282136467763\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.976\n",
      "loss=0.11391270364268112\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.975\n",
      "loss=0.10915165073354194\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.979\n",
      "loss=0.10689984928931713\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9795\n",
      "loss=0.10197311847623386\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.982\n",
      "loss=0.09947404379040059\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.981\n",
      "loss=0.09924055640036682\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9815\n",
      "loss=0.09430652140305269\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9835\n",
      "loss=0.0928001922385987\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.984\n",
      "loss=0.09034794072304685\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.985\n",
      "loss=0.08825277186398839\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9855\n",
      "loss=0.0858297531712173\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.986\n",
      "loss=0.08399187216929363\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.986\n",
      "loss=0.0834493749609419\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.986\n",
      "loss=0.08183561797343891\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9865\n",
      "loss=0.08169613464105359\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.985\n",
      "loss=0.07940655791004693\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.987\n",
      "loss=0.07737718948524402\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9875\n",
      "loss=0.07522896509965042\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9885\n",
      "loss=0.07643873077864874\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9885\n",
      "loss=0.07527880855173212\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9885\n",
      "loss=0.07349930879233944\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9885\n",
      "loss=0.07246292300959856\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9885\n",
      "loss=0.07180729864148436\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9885\n",
      "loss=0.0723951258922535\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9885\n",
      "loss=0.07085364714392538\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.989\n",
      "loss=0.06815336661122555\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.988\n",
      "loss=0.07553127840098456\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.989\n",
      "loss=0.0822671358065778\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9845\n",
      "loss=0.10032352988586928\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.979\n",
      "loss=0.16247130478914967\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9425\n",
      "loss=0.6582475794172788\n",
      "[3 0 3 ... 5 2 0]\n",
      "0.8155\n",
      "loss=0.49872981431739516\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.8585\n",
      "loss=0.61200907336546\n",
      "[5 0 4 ... 5 2 4]\n",
      "0.7885\n",
      "loss=1.2717453748031653\n",
      "[3 0 9 ... 3 2 0]\n",
      "0.6645\n",
      "loss=1.3389832097211245\n",
      "[5 0 4 ... 6 1 6]\n",
      "0.684\n",
      "loss=0.640650145493126\n",
      "[5 0 4 ... 5 8 0]\n",
      "0.8095\n",
      "loss=1.134681647597928\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.735\n",
      "loss=0.564564091272906\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.847\n",
      "loss=0.40249021312308575\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.876\n",
      "loss=0.47618676505988455\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.847\n",
      "loss=0.4029460769343395\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.8745\n",
      "loss=0.37196794925590243\n",
      "[5 0 4 ... 5 2 5]\n",
      "0.881\n",
      "loss=0.3656642079708502\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.8785\n",
      "loss=0.3281845995140037\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.8915\n",
      "loss=0.29933691299880033\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9095\n",
      "loss=0.24327914028758862\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9235\n",
      "loss=0.22301446154126803\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.93\n",
      "loss=0.22844320157668052\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9255\n",
      "loss=0.22239132838326434\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9305\n",
      "loss=0.20617334758543515\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.939\n",
      "loss=0.18488508622990157\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.946\n",
      "loss=0.16751188086788193\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9475\n",
      "loss=0.15909373993431006\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.948\n",
      "loss=0.15532957921280682\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9545\n",
      "loss=0.15412352067021237\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.953\n",
      "loss=0.15352373110133177\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9515\n",
      "loss=0.14831852730982809\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.954\n",
      "loss=0.13848940075609867\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9585\n",
      "loss=0.1281160373277454\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9615\n",
      "loss=0.11944530861004247\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9655\n",
      "loss=0.11326293306752422\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.969\n",
      "loss=0.10845794718565553\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.97\n",
      "loss=0.10401802397007963\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9725\n",
      "loss=0.10002386261201103\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9765\n",
      "loss=0.0965950132181151\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9785\n",
      "loss=0.09313170100482919\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9785\n",
      "loss=0.08900496480594612\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.979\n",
      "loss=0.08571036368365878\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9805\n",
      "loss=0.08243568543655963\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.981\n",
      "loss=0.08054371264210446\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.983\n",
      "loss=0.07891037003714173\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9835\n",
      "loss=0.07689685625006969\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.984\n",
      "loss=0.07482793934161835\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9835\n",
      "loss=0.07303556877087848\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.985\n",
      "loss=0.0716054563958318\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.986\n",
      "loss=0.07059656439658672\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.986\n",
      "loss=0.06956740802148616\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.986\n",
      "loss=0.06851463865592888\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9865\n",
      "loss=0.06743242130011519\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9875\n",
      "loss=0.06644066905587441\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.988\n",
      "loss=0.06546895439651348\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.988\n",
      "loss=0.06439827379905623\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9885\n",
      "loss=0.06382990185270504\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9885\n",
      "loss=0.06314841707042142\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.989\n",
      "loss=0.06256449764599241\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.989\n",
      "loss=0.06217744638614588\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.989\n",
      "loss=0.061589911190110626\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.989\n",
      "loss=0.06122756984734482\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.989\n",
      "loss=0.06071229075593293\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.989\n",
      "loss=0.06043845502155461\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.989\n",
      "loss=0.0603740587012022\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.989\n",
      "loss=0.059640431768429064\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.989\n",
      "loss=0.059524183679680084\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.989\n",
      "loss=0.059748592193714964\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.989\n",
      "loss=0.05888590151093231\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9895\n",
      "loss=0.058363601987338525\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9895\n",
      "loss=0.05810488136626003\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9895\n",
      "loss=0.057930989123995184\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9895\n",
      "loss=0.05814177737694874\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9895\n",
      "loss=0.05977251826006231\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9895\n",
      "loss=0.05775667493274417\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9895\n",
      "loss=0.06378100526738419\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9895\n",
      "loss=0.062379965663098\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.989\n",
      "loss=0.06423969328207707\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9885\n",
      "loss=0.061714833618851\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.989\n",
      "loss=0.06187758658181562\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.989\n",
      "loss=0.062526926243678\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.989\n",
      "loss=0.06125912692213397\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.989\n",
      "loss=0.06043702204041446\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.989\n",
      "loss=0.06042323070690144\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.989\n",
      "loss=0.05985581386884784\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.989\n",
      "loss=0.05914874674248484\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9885\n",
      "loss=0.059000212683168955\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.989\n",
      "loss=0.0586405701925773\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9895\n",
      "loss=0.05795124813016328\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9895\n",
      "loss=0.057614667908460544\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9895\n",
      "loss=0.05748596923769664\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9895\n",
      "loss=0.05708483650683404\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9895\n",
      "loss=0.05669091003188932\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9895\n",
      "loss=0.05654490236608418\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9895\n",
      "loss=0.05618576683491915\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9895\n",
      "loss=0.055821881132030425\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9895\n",
      "loss=0.05565917937598288\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9895\n",
      "loss=0.055482618980853715\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9895\n",
      "loss=0.05513569667080608\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9895\n",
      "loss=0.05484240688359895\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.99\n",
      "loss=0.054707615286763316\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.99\n",
      "loss=0.05456759553197574\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.99\n",
      "loss=0.05420832273426276\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.99\n",
      "loss=0.05411537633701818\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.99\n",
      "loss=0.05390702169418623\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.99\n",
      "loss=0.053761425859831624\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.99\n",
      "loss=0.05350062599634724\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.99\n",
      "loss=0.05337473959721033\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.99\n",
      "loss=0.05333311984208287\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.99\n",
      "loss=0.05322748133855262\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.99\n",
      "loss=0.05308932616367256\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.99\n",
      "loss=0.05320482122058018\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.99\n",
      "loss=0.053446890066890955\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.99\n",
      "loss=0.05295972363887168\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.99\n",
      "loss=0.05357951240352463\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.99\n",
      "loss=0.05312451185552855\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.99\n",
      "loss=0.05333515401888791\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.99\n",
      "loss=0.05231536695223069\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.99\n",
      "loss=0.05334827487112718\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9895\n",
      "loss=0.05287265277137398\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.99\n",
      "loss=0.05441537337095298\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.99\n",
      "loss=0.05316886251276753\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9905\n",
      "loss=0.053538087716665565\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.99\n",
      "loss=0.05352130024035824\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9895\n",
      "loss=0.056916133038814806\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.989\n",
      "loss=0.05652897899054207\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.99\n",
      "loss=0.055679255662321105\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.989\n",
      "loss=0.05558789991050146\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9885\n",
      "loss=0.056036139628492646\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9885\n",
      "loss=0.054431034644526366\n",
      "[5 0 4 ... 5 2 0]\n",
      "0.9895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.train(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=11.886951805136482\n",
      "[7 2 1 ... 1 4 0]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "res = cnn.activate(x_test[:3000],np.array([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 ... 1 4 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_test[:3000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2751\n",
      "0.917\n"
     ]
    }
   ],
   "source": [
    "identical_values_count = np.sum(y_test[:3000] == res)\n",
    "print(identical_values_count)\n",
    "print(identical_values_count/3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def process_image(filename):\n",
    "    # Open the image\n",
    "    image_pil = Image.open(filename)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    image_pil_gray = image_pil.convert(\"L\")\n",
    "\n",
    "    # Resize the image to 28x28\n",
    "    resized_image_gray = image_pil_gray.resize((28, 28))\n",
    "\n",
    "    # Convert to a NumPy array\n",
    "    return np.array(resized_image_gray)\n",
    "\n",
    "# Directory containing the images\n",
    "directory_path = './'  # Update this path\n",
    "\n",
    "# Get list of all image filenames in the directory (assuming they are jpg or png for this example)\n",
    "image_filenames = [os.path.join(directory_path, f) for f in os.listdir(directory_path) if f.endswith(('.jpg'))]\n",
    "\n",
    "# Process each image and store in a list\n",
    "images = [process_image(filename) for filename in image_filenames]\n",
    "\n",
    "# Convert list of processed images to numpy array\n",
    "images_array = np.array(images)\n",
    "\n",
    "print(images_array.shape)  # This will print (num_of_images, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=5.135298763005353\n",
      "[6 6 8 8 6 6]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "res_i = cnn.activate(images_array,np.array([2, 1 ,2 ,2,3 ,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1500 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample labels array (replace this with your own labels)\n",
    "labels = res_i  # This should have the same length as images_array\n",
    "\n",
    "# Number of images to plot\n",
    "num_images = images_array.shape[0]\n",
    "\n",
    "# Create a grid of subplots\n",
    "fig, axes = plt.subplots(int(num_images/6), 6, figsize=(15, 15))\n",
    "\n",
    "for i, ax in enumerate(axes.ravel()):\n",
    "    if i < num_images:\n",
    "        ax.imshow(images_array[i], cmap='gray')\n",
    "        ax.set_title(f\"predict= {labels[i]}\")\n",
    "        ax.axis('off')\n",
    "    else:\n",
    "        ax.axis('off')  # Hide any extra subplots\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
